{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ae96018-2e35-482c-b45b-34c86e6c959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e3167e78-dd6b-4af6-8da5-3727810d0e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc532a277a64e24bdadb71500d2ffd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e904de8-36d2-47c0-a2c3-b66b57722c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MT5ForSequenceClassification were not initialized from the model checkpoint at google/mt5-xxl and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_id = \"google/mt5-xxl\"\n",
    "#model_id = \"google/mt5-xl\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, quantization_config=bnb_config, num_labels=3, device_map={\"\":torch.cuda.current_device()})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "da3f7a07-ac22-4788-b112-3469b02dedf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Блискам ли? '</td>\n",
       "      <td>Тогава бях много емоционален.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matumizi zaidi!</td>\n",
       "      <td>Matumizi hayana manufaa katika hali hii.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Най-очарователната структура на Калтън Хил е Н...</td>\n",
       "      <td>Националният паметник е най-голямата структура...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vigezo vya News ' vinaweza kutoa mzozo kama huu.</td>\n",
       "      <td>Vigezo vipya vinaweza kuleta mzozo.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Helen Gurley Brown, sobre los muchos aspectos ...</td>\n",
       "      <td>Helen Gurley Brown cree que el acoso sexual es...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>เขาเขียนถึงฉันในอีเมล ฉันเชื่อว่าหลักฐานของ To...</td>\n",
       "      <td>อีเมลได้รวมรายละเอียดของหลักฐาน</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Các nhân vật chính nhận được nhiều sự điều trị...</td>\n",
       "      <td>Thật kỳ lạ khi cả nhân vật chính và phụ đều đư...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>一楼是法兰西历史博物馆，珍藏着她一生中唯一已知的圣女贞德肖像和路易十六保存的日记等珍品。</td>\n",
       "      <td>圣女贞德的画像在五楼。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>اس معاملے میں، اس کا بوڑھا دھوکہ دینے والا اس ...</td>\n",
       "      <td>Ginsburg نے اس کی نمائندگی کے باوجود اسے دھوکہ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ngài James gõ bàn một cách khá sốt ruột.</td>\n",
       "      <td>Ngài James đã mất kiên nhẫn.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0                                     'Блискам ли? '   \n",
       "1                                    Matumizi zaidi!   \n",
       "2  Най-очарователната структура на Калтън Хил е Н...   \n",
       "3   Vigezo vya News ' vinaweza kutoa mzozo kama huu.   \n",
       "4  Helen Gurley Brown, sobre los muchos aspectos ...   \n",
       "5  เขาเขียนถึงฉันในอีเมล ฉันเชื่อว่าหลักฐานของ To...   \n",
       "6  Các nhân vật chính nhận được nhiều sự điều trị...   \n",
       "7       一楼是法兰西历史博物馆，珍藏着她一生中唯一已知的圣女贞德肖像和路易十六保存的日记等珍品。   \n",
       "8  اس معاملے میں، اس کا بوڑھا دھوکہ دینے والا اس ...   \n",
       "9           Ngài James gõ bàn một cách khá sốt ruột.   \n",
       "\n",
       "                                          hypothesis  labels  \n",
       "0                      Тогава бях много емоционален.       1  \n",
       "1           Matumizi hayana manufaa katika hali hii.       2  \n",
       "2  Националният паметник е най-голямата структура...       0  \n",
       "3                Vigezo vipya vinaweza kuleta mzozo.       0  \n",
       "4  Helen Gurley Brown cree que el acoso sexual es...       2  \n",
       "5                    อีเมลได้รวมรายละเอียดของหลักฐาน       1  \n",
       "6  Thật kỳ lạ khi cả nhân vật chính và phụ đều đư...       0  \n",
       "7                                        圣女贞德的画像在五楼。       2  \n",
       "8  Ginsburg نے اس کی نمائندگی کے باوجود اسے دھوکہ...       1  \n",
       "9                       Ngài James đã mất kiên nhẫn.       0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"ankitkupadhyay/XNLI\")[\"train\"]\n",
    "\n",
    "data = data.shuffle(seed=1234)  # Shuffle dataset here\n",
    "data = data.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Explore the data\n",
    "df = data.to_pandas()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "96d8928c-ba92-432b-b178-d6fb948f32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.train_test_split(test_size=0.1)\n",
    "train_data = data[\"train\"]\n",
    "test_data = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5a92dc2a-d1fd-41ee-9234-a2a3c6b820dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour sampler 8 exemples par classe\n",
    "def sample_per_class(dataset, num_samples=8):\n",
    "    # Obtenir un index unique pour chaque classe\n",
    "    class_indices = {label: [] for label in set(dataset['labels'])}\n",
    "\n",
    "    # Accumuler les indices pour chaque classe\n",
    "    for index, label in enumerate(dataset['labels']):\n",
    "        class_indices[label].append(index)\n",
    "\n",
    "    # Sélectionner aléatoirement num_samples indices pour chaque classe\n",
    "    import random\n",
    "    sampled_indices = [index for label, indices in class_indices.items()\n",
    "                       for index in random.sample(indices, num_samples)]\n",
    "\n",
    "    # Créer un nouveau dataset à partir des indices échantillonnés\n",
    "    sampled_dataset = dataset.select(sampled_indices)\n",
    "    return sampled_dataset\n",
    "\n",
    "# Appliquer la fonction\n",
    "train_data = sample_per_class(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b5fb654-4d6a-4acf-9416-ac330db138d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_prepare_data(examples):\n",
    "    # Utiliser un format de prompt spécifique pour mT5\n",
    "    task_description = \"Determine if the hypothesis is true based on the premise.\"\n",
    "    text = f\"Task: {task_description} Premise: {examples['premise']} Hypothesis: {examples['hypothesis']}\"\n",
    "    result = tokenizer(text,\n",
    "                       padding=\"max_length\",\n",
    "                       truncation=True,   \n",
    "                       max_length=1000,\n",
    "                       return_overflowing_tokens=True,\n",
    "                       add_special_tokens=True)\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in examples.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result\n",
    "\n",
    "# Apply the tokenization and preparation function\n",
    "train_data = train_data.map(tokenize_and_prepare_data, batched=True)\n",
    "test_data = test_data.map(tokenize_and_prepare_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3836cb6-051a-4679-b2ac-c5336db354d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "df7734a0-80fd-496f-bcb1-b1a9c09077fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fe83356f-d200-4242-a570-11ac6ee57266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9437184 || all params: 7485255683 || trainable%: 0.1260769758531173\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=24,\n",
    "    lora_dropout=0.15,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d3869e9a-9f6d-4830-a7ea-9457e69bb4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]  # Assuming the first element of the tuple is the logits array\n",
    "\n",
    "    # If logits are still in list form or have variable lengths, ensure they are properly converted to a uniform numpy array\n",
    "    if isinstance(logits, list):\n",
    "        max_len = max(len(l) for l in logits)\n",
    "        logits = np.array([np.pad(l, (0, max_len - len(l))) for l in logits])\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = precision_score(labels, predictions, average='weighted')\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision, \n",
    "        \"recall\": recall, \n",
    "        \"f1-score\": f1, \n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ea295cd-3a9e-4af0-b8cf-5ca768c60604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#new code using SFTTrainer\n",
    "import transformers\n",
    "import gc\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Configuration des arguments de l'entraînement\n",
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_ratio=0.08,\n",
    "    learning_rate=1e-4,\n",
    "    output_dir=\"outputs\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    peft_config=lora_config,\n",
    "    args=training_args,\n",
    "    max_seq_length=1024,\n",
    "    data_collator=transformers.DataCollatorWithPadding(tokenizer),\n",
    "    formatting_func=tokenize_and_prepare_data,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8d3b17d7-c790-42d4-9d45-b7b185976029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.24180551369984946, metrics={'train_runtime': 44.7175, 'train_samples_per_second': 0.134, 'train_steps_per_second': 0.067, 'total_flos': 392341192812000.0, 'train_loss': 0.24180551369984946, 'epoch': 3.0})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b8026-20ae-40d2-b0fb-ddcaf8390d26",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80d695af-c1d8-4f86-bddd-d416516946bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "046c2521-469f-4f2c-ba72-7c64448b3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load ANLI test rounds\n",
    "anli_r1 = load_dataset(\"anli\", split=\"train_r1[:5%]\")\n",
    "anli_r2 = load_dataset(\"anli\", split=\"train_r2[:5%]\")\n",
    "anli_r3 = load_dataset(\"anli\", split=\"train_r3[:3%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "383cea87-b82c-4588-8552-3cf7528b81cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771db85285bd4a2dac6f8ecb2023779b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to process the ANLI dataset rounds\n",
    "def process_anli_data(dataset):\n",
    "    # Tokenize the data\n",
    "    dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "    dataset = dataset.map(tokenize_and_prepare_data, batched=True, remove_columns=[col for col in dataset.column_names if col not in ['premise', 'hypothesis', 'labels']])\n",
    "    return dataset\n",
    "\n",
    "# Step 2: Process the data\n",
    "anli_r1 = process_anli_data(anli_r1)\n",
    "anli_r2 = process_anli_data(anli_r2)\n",
    "anli_r3 = process_anli_data(anli_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3e6b1a0f-15b8-414f-a584-17a180d34af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ANLI R1\n",
      "Evaluating ANLI R2\n",
      "Evaluating ANLI R3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2387838400666389\n",
      "Recall: 0.3942857142857143\n",
      "F1-score: 0.2336518936518937\n",
      "Accuracy: 0.3942857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define predict function with metrics\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "def predict_and_evaluate(dataset):\n",
    "    with torch.inference_mode():\n",
    "        predictions = trainer.evaluate(dataset)\n",
    "    print(\"Precision:\", predictions['eval_precision'])\n",
    "    print(\"Recall:\", predictions['eval_recall'])\n",
    "    print(\"F1-score:\", predictions['eval_f1-score'])\n",
    "    print(\"Accuracy:\", predictions['eval_accuracy'])\n",
    "\n",
    "# Step 4: Run predictions and compute metrics for each ANLI round\n",
    "print(\"Evaluating ANLI R1\")\n",
    "#predict_and_evaluate(anli_r1)\n",
    "\n",
    "print(\"Evaluating ANLI R2\")\n",
    "#predict_and_evaluate(anli_r2)\n",
    "\n",
    "print(\"Evaluating ANLI R3\")\n",
    "predict_and_evaluate(anli_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed8597-2f03-411c-84dc-fc20a7161593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
