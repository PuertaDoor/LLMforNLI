{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae96018-2e35-482c-b45b-34c86e6c959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3167e78-dd6b-4af6-8da5-3727810d0e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1988d28347d946fc8b8bfce416883f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e904de8-36d2-47c0-a2c3-b66b57722c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4bea355af84fdead76e4dfc4c6477b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at lightblue/suzume-llama-3-8B-multilingual and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"lightblue/suzume-llama-3-8B-multilingual\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, quantization_config=bnb_config, num_labels=3, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3f7a07-ac22-4788-b112-3469b02dedf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Блискам ли? '</td>\n",
       "      <td>Тогава бях много емоционален.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matumizi zaidi!</td>\n",
       "      <td>Matumizi hayana manufaa katika hali hii.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Най-очарователната структура на Калтън Хил е Н...</td>\n",
       "      <td>Националният паметник е най-голямата структура...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vigezo vya News ' vinaweza kutoa mzozo kama huu.</td>\n",
       "      <td>Vigezo vipya vinaweza kuleta mzozo.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Helen Gurley Brown, sobre los muchos aspectos ...</td>\n",
       "      <td>Helen Gurley Brown cree que el acoso sexual es...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>เขาเขียนถึงฉันในอีเมล ฉันเชื่อว่าหลักฐานของ To...</td>\n",
       "      <td>อีเมลได้รวมรายละเอียดของหลักฐาน</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Các nhân vật chính nhận được nhiều sự điều trị...</td>\n",
       "      <td>Thật kỳ lạ khi cả nhân vật chính và phụ đều đư...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>一楼是法兰西历史博物馆，珍藏着她一生中唯一已知的圣女贞德肖像和路易十六保存的日记等珍品。</td>\n",
       "      <td>圣女贞德的画像在五楼。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>اس معاملے میں، اس کا بوڑھا دھوکہ دینے والا اس ...</td>\n",
       "      <td>Ginsburg نے اس کی نمائندگی کے باوجود اسے دھوکہ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ngài James gõ bàn một cách khá sốt ruột.</td>\n",
       "      <td>Ngài James đã mất kiên nhẫn.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0                                     'Блискам ли? '   \n",
       "1                                    Matumizi zaidi!   \n",
       "2  Най-очарователната структура на Калтън Хил е Н...   \n",
       "3   Vigezo vya News ' vinaweza kutoa mzozo kama huu.   \n",
       "4  Helen Gurley Brown, sobre los muchos aspectos ...   \n",
       "5  เขาเขียนถึงฉันในอีเมล ฉันเชื่อว่าหลักฐานของ To...   \n",
       "6  Các nhân vật chính nhận được nhiều sự điều trị...   \n",
       "7       一楼是法兰西历史博物馆，珍藏着她一生中唯一已知的圣女贞德肖像和路易十六保存的日记等珍品。   \n",
       "8  اس معاملے میں، اس کا بوڑھا دھوکہ دینے والا اس ...   \n",
       "9           Ngài James gõ bàn một cách khá sốt ruột.   \n",
       "\n",
       "                                          hypothesis  labels  \n",
       "0                      Тогава бях много емоционален.       1  \n",
       "1           Matumizi hayana manufaa katika hali hii.       2  \n",
       "2  Националният паметник е най-голямата структура...       0  \n",
       "3                Vigezo vipya vinaweza kuleta mzozo.       0  \n",
       "4  Helen Gurley Brown cree que el acoso sexual es...       2  \n",
       "5                    อีเมลได้รวมรายละเอียดของหลักฐาน       1  \n",
       "6  Thật kỳ lạ khi cả nhân vật chính và phụ đều đư...       0  \n",
       "7                                        圣女贞德的画像在五楼。       2  \n",
       "8  Ginsburg نے اس کی نمائندگی کے باوجود اسے دھوکہ...       1  \n",
       "9                       Ngài James đã mất kiên nhẫn.       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"ankitkupadhyay/XNLI\")[\"train\"]\n",
    "\n",
    "data = data.shuffle(seed=1234)  # Shuffle dataset here\n",
    "data = data.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Explore the data\n",
    "df = data.to_pandas()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d8928c-ba92-432b-b178-d6fb948f32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.train_test_split(test_size=0.1)\n",
    "train_data = data[\"train\"]\n",
    "test_data = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a92dc2a-d1fd-41ee-9234-a2a3c6b820dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour sampler 8 exemples par classe\n",
    "def sample_per_class(dataset, num_samples=8):\n",
    "    # Obtenir un index unique pour chaque classe\n",
    "    class_indices = {label: [] for label in set(dataset['labels'])}\n",
    "\n",
    "    # Accumuler les indices pour chaque classe\n",
    "    for index, label in enumerate(dataset['labels']):\n",
    "        class_indices[label].append(index)\n",
    "\n",
    "    # Sélectionner aléatoirement num_samples indices pour chaque classe\n",
    "    import random\n",
    "    sampled_indices = [index for label, indices in class_indices.items()\n",
    "                       for index in random.sample(indices, num_samples)]\n",
    "\n",
    "    # Créer un nouveau dataset à partir des indices échantillonnés\n",
    "    sampled_dataset = dataset.select(sampled_indices)\n",
    "    return sampled_dataset\n",
    "\n",
    "# Appliquer la fonction\n",
    "train_data = sample_per_class(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5fb654-4d6a-4acf-9416-ac330db138d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f160159e6c604d60862cdbf1b5ad6aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb93e668c31471a92369201bf694bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/589053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_prepare_data(examples):\n",
    "    # Tokeniser chaque texte dans le batch\n",
    "    text = f\"Is this true? {examples['premise']} implies {examples['hypothesis']}\"\n",
    "    result = tokenizer(text,truncation=True,   \n",
    "                       max_length=1000,\n",
    "                       return_overflowing_tokens=True)\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in examples.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Apply the tokenization and preparation function\n",
    "train_data = train_data.map(tokenize_and_prepare_data, batched=True)\n",
    "test_data = test_data.map(tokenize_and_prepare_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3836cb6-051a-4679-b2ac-c5336db354d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7734a0-80fd-496f-bcb1-b1a9c09077fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe83356f-d200-4242-a570-11ac6ee57266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3420160 || all params: 4018696192 || trainable%: 0.08510620949173757\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=24,\n",
    "    lora_dropout=0.15,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3869e9a-9f6d-4830-a7ea-9457e69bb4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred  # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Calculate metrics, assuming 'average' as 'weighted' for handling multiclass classification\n",
    "    precision = precision_score(labels, predictions, average='weighted')\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Return a dictionary with the computed metrics\n",
    "    return {\n",
    "        \"precision\": precision, \n",
    "        \"recall\": recall, \n",
    "        \"f1-score\": f1, \n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea295cd-3a9e-4af0-b8cf-5ca768c60604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#new code using SFTTrainer\n",
    "import transformers\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Configuration des arguments de l'entraînement\n",
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_ratio=0.08,\n",
    "    learning_rate=1e-4,\n",
    "    output_dir=\"outputs\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    peft_config=lora_config,\n",
    "    args=training_args,\n",
    "    max_seq_length=1024,\n",
    "    data_collator=transformers.DataCollatorWithPadding(tokenizer),\n",
    "    formatting_func=tokenize_and_prepare_data,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d3b17d7-c790-42d4-9d45-b7b185976029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.9407986005147299, metrics={'train_runtime': 24.6741, 'train_samples_per_second': 0.243, 'train_steps_per_second': 0.122, 'total_flos': 251388739584000.0, 'train_loss': 0.9407986005147299, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b8026-20ae-40d2-b0fb-ddcaf8390d26",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d695af-c1d8-4f86-bddd-d416516946bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "046c2521-469f-4f2c-ba72-7c64448b3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load ANLI test rounds\n",
    "anli_r1 = load_dataset(\"anli\", split=\"train_r1[:10%]\")\n",
    "anli_r2 = load_dataset(\"anli\", split=\"train_r2[:10%]\")\n",
    "anli_r3 = load_dataset(\"anli\", split=\"train_r3[:10%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "383cea87-b82c-4588-8552-3cf7528b81cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39d3dedd5cc477ba9212c19cda95157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f21c647e4ea4b69a85ada817ab09688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4546 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a11d1183fb04413b29d72f039260291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to process the ANLI dataset rounds\n",
    "def process_anli_data(dataset):\n",
    "    # Tokenize the data\n",
    "    dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "    dataset = dataset.map(tokenize_and_prepare_data, batched=True, remove_columns=[col for col in dataset.column_names if col not in ['premise', 'hypothesis', 'labels']])\n",
    "    return dataset\n",
    "\n",
    "# Step 2: Process the data\n",
    "anli_r1 = process_anli_data(anli_r1)\n",
    "anli_r2 = process_anli_data(anli_r2)\n",
    "anli_r3 = process_anli_data(anli_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e6b1a0f-15b8-414f-a584-17a180d34af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ANLI R1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5415686495386853\n",
      "Recall: 0.4658385093167702\n",
      "F1-score: 0.49771965276113617\n",
      "Accuracy: 0.4658385093167702\n",
      "Evaluating ANLI R2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6721870174130677\n",
      "Recall: 0.44075829383886256\n",
      "F1-score: 0.5057540165720672\n",
      "Accuracy: 0.44075829383886256\n",
      "Evaluating ANLI R3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu4/21200044/stage/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.36966582017785765\n",
      "Recall: 0.35599078341013823\n",
      "F1-score: 0.36202093284097037\n",
      "Accuracy: 0.35599078341013823\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define predict function with metrics\n",
    "def predict_and_evaluate(dataset):\n",
    "    predictions = trainer.evaluate(dataset)\n",
    "    print(\"Precision:\", predictions['eval_precision'])\n",
    "    print(\"Recall:\", predictions['eval_recall'])\n",
    "    print(\"F1-score:\", predictions['eval_f1-score'])\n",
    "    print(\"Accuracy:\", predictions['eval_accuracy'])\n",
    "\n",
    "# Step 4: Run predictions and compute metrics for each ANLI round\n",
    "print(\"Evaluating ANLI R1\")\n",
    "predict_and_evaluate(anli_r1)\n",
    "\n",
    "print(\"Evaluating ANLI R2\")\n",
    "predict_and_evaluate(anli_r2)\n",
    "\n",
    "print(\"Evaluating ANLI R3\")\n",
    "predict_and_evaluate(anli_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed8597-2f03-411c-84dc-fc20a7161593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
